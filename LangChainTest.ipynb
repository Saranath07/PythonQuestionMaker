{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgfPmNLm8oFy"
      },
      "source": [
        "# Installing Lang Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8j-VHkAX7JJu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain\n",
            "  Obtaining dependency information for langchain from https://files.pythonhosted.org/packages/3f/ae/a5ac2059e8dcc326f8ad4e10d907f6fdf1f920ab060020f12ad64ca26172/langchain-0.2.6-py3-none-any.whl.metadata\n",
            "  Downloading langchain-0.2.6-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /Users/saranath/anaconda3/lib/python3.11/site-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/saranath/anaconda3/lib/python3.11/site-packages (from langchain) (2.0.25)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/saranath/anaconda3/lib/python3.11/site-packages (from langchain) (3.8.5)\n",
            "Collecting langchain-core<0.3.0,>=0.2.10 (from langchain)\n",
            "  Obtaining dependency information for langchain-core<0.3.0,>=0.2.10 from https://files.pythonhosted.org/packages/cd/79/319f4898ce837e62d3611ed5da9246d10e3a966bb60fadb54901563867cf/langchain_core-0.2.10-py3-none-any.whl.metadata\n",
            "  Downloading langchain_core-0.2.10-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Obtaining dependency information for langchain-text-splitters<0.3.0,>=0.2.0 from https://files.pythonhosted.org/packages/06/76/9e0ca1b8881f64bf927f2205bf6c43a085c04646a71d911b3c05d76e90bb/langchain_text_splitters-0.2.2-py3-none-any.whl.metadata\n",
            "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Obtaining dependency information for langsmith<0.2.0,>=0.1.17 from https://files.pythonhosted.org/packages/11/4f/1d89e18d542b4545787a806dd8b485b5178781cd6c99e7c79285fd862a34/langsmith-0.1.82-py3-none-any.whl.metadata\n",
            "  Downloading langsmith-0.1.82-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /Users/saranath/anaconda3/lib/python3.11/site-packages (from langchain) (1.24.3)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /Users/saranath/anaconda3/lib/python3.11/site-packages (from langchain) (1.10.8)\n",
            "Requirement already satisfied: requests<3,>=2 in /Users/saranath/anaconda3/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/saranath/anaconda3/lib/python3.11/site-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/saranath/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/saranath/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/saranath/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/saranath/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/saranath/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/saranath/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/saranath/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.10->langchain)\n",
            "  Obtaining dependency information for jsonpatch<2.0,>=1.33 from https://files.pythonhosted.org/packages/73/07/02e16ed01e04a374e644b575638ec7987ae846d25ad97bcc9945a3ee4b0e/jsonpatch-1.33-py2.py3-none-any.whl.metadata\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting packaging<25,>=23.2 (from langchain-core<0.3.0,>=0.2.10->langchain)\n",
            "  Obtaining dependency information for packaging<25,>=23.2 from https://files.pythonhosted.org/packages/08/aa/cc0199a5f0ad350994d660967a8efb233fe0416e4639146c089643407ce6/packaging-24.1-py3-none-any.whl.metadata\n",
            "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Obtaining dependency information for orjson<4.0.0,>=3.9.14 from https://files.pythonhosted.org/packages/5b/0d/96079bcd0d7f6cda1719c1cbb07bb136049123f46b70be085610f625f6cd/orjson-3.10.5-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata\n",
            "  Downloading orjson-3.10.5-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.2.0 in /Users/saranath/anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (4.7.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/saranath/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/saranath/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/saranath/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /Users/saranath/anaconda3/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /Users/saranath/anaconda3/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.10->langchain) (2.1)\n",
            "Downloading langchain-0.2.6-py3-none-any.whl (975 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m975.5/975.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.2.10-py3-none-any.whl (332 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m332.8/332.8 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Downloading langsmith-0.1.82-py3-none-any.whl (127 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.4/127.4 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading orjson-3.10.5-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (258 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.7/258.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: packaging, orjson, jsonpatch, langsmith, langchain-core, langchain-text-splitters, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 23.1\n",
            "    Uninstalling packaging-23.1:\n",
            "      Successfully uninstalled packaging-23.1\n",
            "  Attempting uninstall: jsonpatch\n",
            "    Found existing installation: jsonpatch 1.32\n",
            "    Uninstalling jsonpatch-1.32:\n",
            "      Successfully uninstalled jsonpatch-1.32\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\n",
            "tables 3.8.0 requires cython>=0.29.21, which is not installed.\n",
            "spyder 5.4.3 requires pyqt5<5.16, which is not installed.\n",
            "spyder 5.4.3 requires pyqtwebengine<5.16, which is not installed.\n",
            "python-lsp-black 1.2.1 requires black>=22.3.0, but you have black 0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed jsonpatch-1.33 langchain-0.2.6 langchain-core-0.2.10 langchain-text-splitters-0.2.2 langsmith-0.1.82 orjson-3.10.5 packaging-24.1\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open('apiKeys.json', 'r') as file:\n",
        "    apiKeys = json.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOtKJQxE7Qx9",
        "outputId": "9287a3a4-9065-470b-97de-aaecf065e263"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = apiKeys['LANGCHAIN_API_KEY']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kgnnz3nF7u7b",
        "outputId": "5b65a1e3-fbcb-4172-aad5-9f0186195182"
      },
      "outputs": [],
      "source": [
        "!pip install -qU langchain-groq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17vVcHJ88yvo"
      },
      "source": [
        "# Importing Llama3 8B model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6FEBB5K7yI9",
        "outputId": "e8bc61f7-6ad8-49ce-c9ef-9277571f6d6f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = apiKeys['GROQ_API_KEY']\n",
        "\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "model = ChatGroq(model=\"llama3-8b-8192\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rs0WZ1TA8sLt"
      },
      "source": [
        "# Checking if the model is working with some common prompts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkcyxd2n8fWF",
        "outputId": "18edc3b2-8330-4cc6-fded-37be7651a00e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='வணக்கம்! (Vanaakkam!)', response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 24, 'total_tokens': 43, 'completion_time': 0.014450676, 'prompt_time': 0.004392386, 'queue_time': None, 'total_time': 0.018843062}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_c4a72fb330', 'finish_reason': 'stop', 'logprobs': None}, id='run-b56d7ea1-ad82-4049-bf2b-f8a609a25245-0', usage_metadata={'input_tokens': 24, 'output_tokens': 19, 'total_tokens': 43})"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"Translate the following from English into Tamil\"),\n",
        "    HumanMessage(content=\"hi!\"),\n",
        "]\n",
        "\n",
        "model.invoke(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjBOD_hp835X"
      },
      "source": [
        "# Checking for python oriented content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ii7q6MFn86dz",
        "outputId": "2d534d4f-efe1-4b54-c112-5528e0646b48"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='Getting good with programming in Python requires a combination of skills, knowledge, and practice. Here are some tips to help you improve your Python programming skills:\\n\\n1. **Start with the basics**: Make sure you have a solid understanding of the basic syntax, data types, variables, control structures, functions, and object-oriented programming concepts in Python.\\n\\n2. **Practice, practice, practice**: The best way to learn Python is by writing code. Start with simple programs and gradually move on to more complex ones. Practice solving problems on platforms like LeetCode, HackerRank, or CodeWars.\\n\\n3. **Work on projects**: Apply your knowledge by working on real-world projects. This will help you identify areas where you need to improve and give you a sense of accomplishment as you complete your projects.\\n\\n4. **Learn from others**: Read open-source code, participate in online communities like Reddit\\'s r/learnpython, and join online forums to learn from others and get feedback on your code.\\n\\n5. **Use a Python IDE**: A Python Integrated Development Environment (IDE) like PyCharm, Spyder, or Visual Studio Code can help you write, run, and debug your code more efficiently.\\n\\n6. **Read documentation and tutorials**: The official Python documentation and tutorials are an excellent resource to learn Python.\\n\\n7. **Take online courses**: There are many online courses and tutorials available that can help you learn Python. Some popular options include Codecademy, DataCamp, and Coursera.\\n\\n8. **Join online communities**: Join online communities like Reddit\\'s r/Python, Stack Overflow, and Python subreddit to connect with other Python programmers, get help with your code, and learn from their experiences.\\n\\n9. **Read books**: There are many excellent books on Python programming that can help you improve your skills. Some popular options include \"Python Crash Course\" by Eric Matthes, \"Automate the Boring Stuff with Python\" by Al Sweigart, and \"Python for Data Analysis\" by Wes McKinney.\\n\\n10. **Participate in coding challenges**: Participate in coding challenges like Google Code Jam, Facebook Hacker Cup, or Python Challenges to test your skills and learn from others.\\n\\n11. **Learn advanced topics**: Once you have a solid foundation in Python, focus on learning advanced topics like decorators, generators, asynchronous programming, and machine learning.\\n\\n12. **Stay up-to-date**: Python is a rapidly evolving language, and new libraries, frameworks, and tools are being developed all the time. Stay up-to-date by following Python blogs, attending conferences, and reading newsletters.\\n\\nRemember, getting good with programming in Python takes time, effort, and dedication. Keep practicing, and you\\'ll see improvement over time.', response_metadata={'token_usage': {'completion_tokens': 548, 'prompt_tokens': 33, 'total_tokens': 581, 'completion_time': 0.446570421, 'prompt_time': 0.005634941, 'queue_time': None, 'total_time': 0.452205362}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_6a6771ae9c', 'finish_reason': 'stop', 'logprobs': None}, id='run-cb5843bb-ab30-4f00-bbc4-24e866bc523e-0', usage_metadata={'input_tokens': 33, 'output_tokens': 548, 'total_tokens': 581})"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"Give a resanoble answer to the questions\"),\n",
        "    HumanMessage(content=\"How to get good with programming in python?\"),\n",
        "]\n",
        "\n",
        "model.invoke(messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dtDUStrv-d8R"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "messages_1 = [\n",
        "    SystemMessage(content=\"Give a problem statement based on the interest of user along with test cases\"),\n",
        "    HumanMessage(content=\"I like attack on titan and that is one of my favorite animie\"),\n",
        "    HumanMessage(content=\"I am weak in string operations of python\")\n",
        "]\n",
        "\n",
        "response_1 = model.invoke(messages_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"question_1.md\", \"w\") as file:\n",
        "    file.write(response_1.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Interactive LangChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello! I am your python assistant\n",
            "Share your interests and the concepts you are weak, I will help you out!!\n",
            "press Q to quit the conversation\n",
            "Hi, I am saranath. I love to watch cricket and recently india won the wc\n",
            "Hello Saranath! Nice to meet you! Congratulations to the Indian cricket team on their recent World Cup win! What's your favorite aspect of the game - batting, bowling, or fielding?\n",
            "I think it was a good team effort\n",
            "Yeah, it was a fantastic team effort! The Indian team's performance was impressive throughout the tournament. I'm glad you're a cricket fan! Do you have a favorite player or a favorite team besides India?\n",
            "Beside cricket i am learning programming. I am prettyy weak in working with functions. Can you help me out\n",
            "I'd be happy to help you with functions. Can you tell me a bit more about what you're struggling with? For example, are you having trouble defining functions, calling functions, or something else?\n",
            "Yes\n",
            "I'd be happy to help you with functions in programming. Can you tell me what specifically you're struggling with? Would you like to practice writing a function to solve a problem, or do you have a specific question about how functions work?\n",
            "\n",
            "Also, do you have a preferred programming language you're learning, or would you like me to suggest a problem in a language you're comfortable with?\n",
            "Respond\n",
            "I'd be happy to help you with functions. Can you tell me what specifically you're struggling with? Do you have a particular problem or topic in mind that you'd like to work on?\n",
            "I would love if i get some examples in python\n",
            "Let's take a simple example of a function that calculates the area of a rectangle. Can you think of a problem related to cricket that you would like to solve using a function in Python? \n",
            "\n",
            "For example, you could write a function to calculate the total runs scored by a batsman in a match or the total wickets taken by a bowler.\n",
            "\n",
            "Let me know if you have any idea or if you would like me to provide a problem statement.\n",
            "respond\n",
            "Here's a simple problem statement and its solution in Python. You can try to solve it yourself and then compare your answer with the solution:\n",
            "\n",
            "Problem: Write a Python function to calculate the area of a rectangle given its length and breadth.\n",
            "\n",
            "Solution:\n",
            "```\n",
            "def calculate_area(length, breadth):\n",
            "    return length * breadth\n",
            "\n",
            "# Test cases:\n",
            "print(calculate_area(5, 3))  # Expected output: 15\n",
            "print(calculate_area(10, 2))  # Expected output: 20\n",
            "print(calculate_area(7, 4))   # Expected output: 28\n",
            "```\n",
            "\n",
            "This problem is a great example to practice working with functions in Python. Can you try to solve it yourself?\n",
            "Bye\n",
            "Here's a Python problem statement related to your interest in cricket and your weakness in working with functions:\n",
            "\n",
            "Problem: Write a Python function `calculate_total_runs` that takes a list of innings scores as input and returns the total runs scored by the team. The function should also calculate the average runs scored per innings. \n",
            "\n",
            "Example test cases:\n",
            "\n",
            "- `calculate_total_runs([100, 200, 150, 250])` should return `(600, 150.0)`\n",
            "- `calculate_total_runs([50, 70, 80, 90])` should return `(390, 97.5)`\n",
            "\n",
            "Can you try to solve this problem and then I'll help you with any issues you might have?\n"
          ]
        }
      ],
      "source": [
        "messages_2 = [\n",
        "    SystemMessage(content=\"Chat with the user as a normal python chatbot and only give questions when user asks.\"),\n",
        "    SystemMessage(content=\"Give a python problem statement based on the interests of the user along with test cases.\")\n",
        "]\n",
        "\n",
        "print(\"Hello! I am your python assistant\")\n",
        "print(\"Share your interests and the concepts you are weak, I will help you out!!\")\n",
        "print(\"press Q to quit the conversation\")\n",
        "\n",
        "ch = input()\n",
        "\n",
        "while ch != 'Q' and ch != 'q':\n",
        "    print(ch)\n",
        "    messages_2.append(HumanMessage(content=ch))\n",
        "    response_2 = model.invoke(messages_2)\n",
        "    print(response_2.content)\n",
        "    ch = input()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[SystemMessage(content='Chat with the user as a normal python chatbot and only give questions when user asks.'),\n",
              " SystemMessage(content='Give a python problem statement based on the interests of the user along with test cases.'),\n",
              " HumanMessage(content='Hi, I am saranath. I love to watch cricket and recently india won the wc'),\n",
              " HumanMessage(content='I think it was a good team effort'),\n",
              " HumanMessage(content='Beside cricket i am learning programming. I am prettyy weak in working with functions. Can you help me out'),\n",
              " HumanMessage(content='Yes'),\n",
              " HumanMessage(content='Respond'),\n",
              " HumanMessage(content='I would love if i get some examples in python'),\n",
              " HumanMessage(content='respond'),\n",
              " HumanMessage(content='Bye')]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "messages_2\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
